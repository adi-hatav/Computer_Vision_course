{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://img.icons8.com/bubbles/100/000000/3d-glasses.png\" style=\"height:50px;display:inline\"> EE 046746 - Technion - Computer Vision\n",
    "\n",
    "\n",
    "## Homework 4 - Structure From Motion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/dusk/64/000000/python.png\" style=\"height:50px;display:inline\"> Python Libraries\n",
    "---\n",
    "\n",
    "* `numpy`\n",
    "* `matplotlib`\n",
    "* `opencv` (or `scikit-image`)\n",
    "* `scikit-learn`\n",
    "* `scipy`\n",
    "* Anything else you need (`os`, `pandas`, `csv`, `json`,...)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:12:02.239151Z",
     "start_time": "2024-08-21T17:12:00.196593Z"
    }
   },
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# for visualization windows to pop out in jupyter (kernel may require restart after using GUIs)\n",
    "%matplotlib qt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Tasks\n",
    "---\n",
    "* In all tasks, you should document your process and results in a report file (which will be saved as `.pdf`). \n",
    "* You can reference your code in the report file, but no need for actual code in this file, the code is submitted in a seprate folder as explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/external-itim2101-lineal-color-itim2101/64/000000/external-robot-engineering-itim2101-lineal-color-itim2101.png\" style=\"height:50px;display:inline\"> Introduction \n",
    "---\n",
    "One of the major areas of computer vision is 3D reconstruction. Given several 2D images of an environment, can we recover the 3D structure of the environment, as well as the position of the camera/robot? This has many uses in robotics and autonomous systems, as understanding the 3D structure of the environment is crucial to navigation. You don't want your robot constantly bumping into walls, or running over human beings!\n",
    "\n",
    "<center> <img src=\"https://research.qut.edu.au/qcr/wp-content/uploads/sites/305/2021/02/Challenge_summary_pic-768x513.jpg\" style=\"height:300px\">\n",
    "<center> Image Source - <a href=\"https://research.qut.edu.au/qcr/2021/02/17/2nd-robotic-vision-scene-understanding-challenge-launched-cvpr2021-embodied-ai-workshop/\"> CVPR 21 Embodied AI Workshop </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 1, you will be writing a set of functions to generate a sparse point cloud for some test images we have provided to you. The test images are 2 renderings of a temple from two different angles. We have also provided you with a `npz` file containing good point correspondences between the two images. You will first write a function that computes the fundamental matrix between the two images. Then write a function that uses the epipolar constraint to find more point matches between the two images. Finally, you will write a function that will triangulate the 3D points for each pair of 2D point correspondences.\n",
    "\n",
    "In Part 2, you will be writing a set of functions to calibrate a camera and project a 3D CAD model to a 2D image after estimating the camera pose. We have provided you with a `npz` file containing corresponding 2D-3D pairs. You will first write a function that estimates a camera matrix given 2D-3D calibration points. Then write a function to decompose the estimated camera matrix to intrinsic/extrinsic parameters. Finally, you will write a script to project the provided 3D CAD model and compare it to a given 2D image of an airplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/pastel-glyph/64/000000/pain-points.png\" style=\"height:50px;display:inline\"> Part 1 - Sparse Reconstruction \n",
    "---\n",
    "In this section, you will be writing a set of function to compute the sparse reconstruction from two sample images of a temple. You will first estimate the Fundamental matrix, compute point correspondences, then plot the results in 3D.\n",
    "It may be helpful to read through Section 1.5 right now. In Section 1.5 we ask you to write a testing script that will run your whole pipeline. It will be easier to start that now and add to it as you complete each of the questions one after the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Eight Point Algorithm\n",
    "---\n",
    "In this question, you're going to use the eight point algorithm which is covered in class to estimate the fundamental matrix. Please use the point correspondences provided in `data/some_corresp.npz`; you can load and view the contents of a `.npz` file as follows:\n",
    "> ``data = np.load(\"./Users/yiftachedelstain/ee046746-computer-vision-private/HW/hw4_structure_from_motion/data/some_corresp.npz\")``\n",
    "<br> `` print(data.files)`` </br>\n",
    "\n",
    "* Write the following function:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:12:13.365891Z",
     "start_time": "2024-08-21T17:12:13.181697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load(\"./data/some_corresp.npz\")\n",
    "# plot the points on im1 and im2\n",
    "im1 = cv.imread(\"./data/im1.png\")\n",
    "im2 = cv.imread(\"./data/im2.png\")\n",
    "plt.imshow(im1)\n",
    "plt.scatter(data['pts1'][:,0], data['pts1'][:,1], c='r', s=10)\n",
    "plt.show()\n",
    "plt.imshow(im2)\n",
    "plt.scatter(data['pts2'][:,0], data['pts2'][:,1], c='r', s=10)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:12:22.740507Z",
     "start_time": "2024-08-21T17:12:22.723955Z"
    }
   },
   "source": [
    "def eight_point(pts1, pts2, pmax):\n",
    "    \"\"\"\n",
    "    Eight Point Algorithm\n",
    "    [I] pts1, points in image 1 (Nx2 matrix)\n",
    "        pts2, points in image 2 (Nx2 matrix)\n",
    "        pmax, scalar value computed as max(H1,W1)\n",
    "    [O] F, the fundamental matrix (3x3 matrix)\n",
    "    \"\"\"\n",
    "    # Step 1: Normalize the points\n",
    "    T = np.array([[1/pmax, 0, 0], [0, 1/pmax, 0], [0, 0, 1]])\n",
    "    pts1_homog = np.concatenate([pts1, np.ones((pts1.shape[0], 1))], axis=1)\n",
    "    pts2_homog = np.concatenate([pts2, np.ones((pts2.shape[0], 1))], axis=1)\n",
    "    \n",
    "    pts1_normalized = (T @ pts1_homog.T).T\n",
    "    pts2_normalized = (T @ pts2_homog.T).T\n",
    "    \n",
    "    # Step 2: Construct the matrix A\n",
    "    A = np.zeros((pts1.shape[0], 9))\n",
    "    for i in range(pts1.shape[0]):\n",
    "        x1, y1 = pts1_normalized[i, 0], pts1_normalized[i, 1]\n",
    "        x2, y2 = pts2_normalized[i, 0], pts2_normalized[i, 1]\n",
    "        A[i] = [x2*x1, x2*y1, x2, y2*x1, y2*y1, y2, x1, y1, 1]\n",
    "    \n",
    "    # Step 3: Compute the fundamental matrix F\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    F = V[-1].reshape(3, 3)\n",
    "    \n",
    "    # Step 4: Enforce the rank-2 constraint\n",
    "    F = _singularize(F)\n",
    "    \n",
    "    # Step 5: Un-normalize the fundamental matrix\n",
    "    F = T.T @ F @ T\n",
    "    \n",
    "    return F\n",
    "\n",
    "def _singularize(F):\n",
    "    U, S, V = np.linalg.svd(F)\n",
    "    S[-1] = 0\n",
    "    F = U @ np.diag(S) @ V\n",
    "    return F\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `pts1` and `pts2` are $N \\times 2$ matrices corresponding to the $(x,y)$ coordinates of the $N$ points in the first and second image respectively, and `pmax` is a scale parameter. Implementation tips:\n",
    "* Normalize points and un-normalize $F$: You should scale the data by dividing each coordinate by $p_{\\text{max}}$ (the maximum of the image's width and height) using a transformation matrix $T$. After computing $F$, you will have to \"unscale\" the fundamental matrix. If $p_{\\text{norm}} = Tp$, then $F_{\\text{unnorm}} = T^T F T$. Note that this scaling is slightly simpler than \"centering\" that you did in the lecture, but for the purpose of this assingment it should suffice.\n",
    "\n",
    "* You must enforce the rank 2 constraint on $F$ before unscaling. Recall that a valid fundamental matrix $F$ will have all epipolar lines intersect at a certain point, meaning that there exists a non-trivial null space for $F$. In general, with real points, the eight-point solution for $F$ will not come with this condition. To enforce the rank 2 constraint, decompose $F$ with SVD to get the three matrices $U,\\Sigma,V$ such that $F = U\\Sigma V^T$. Then force the matrix to be rank 2 by setting the smallest singular value in $\\Sigma$ to zero, giving you a new $\\Sigma'$. Now compute the proper fundamental matrix with $F' = U\\Sigma' V^T$.\n",
    "\n",
    "* You may find it helpful to refine the solution by using local minimization. This probably won't fix a completely broken solution, but may make a good solution better by locally minimizing a geometric cost function. For this we have provided a helper function `refineF` taking in $F$ and the two sets of points, which you can call from `eight_point` before unscaling $F$.\n",
    "\n",
    "* Remember that the x-coordinate of a point in the image is its column entry and y-coordinate is the row entry. Also note that eight-point is just a \"figurative\" name, it just means that you need at least 8 points; your algorithm should use an over-determined system ($N > 8$ points).\n",
    "\n",
    "* To visualize the correctness of your estimated $F$, use the provided function `displayEpipolarF`, which takes in $F$, and the two images. This GUI lets you select a point in one of the images and visualize the corresponding epipolar line in the other image (Figure 1).\n",
    "\n",
    "*  Please include in your report the recovered $F$ and the visualization of some epipolar lines (similar to Figure 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:12:32.427506Z",
     "start_time": "2024-08-21T17:12:32.413027Z"
    }
   },
   "source": [
    "# helper function 1: singualrizes F using SVD\n",
    "def _singularize(F):\n",
    "    U, S, V = np.linalg.svd(F)\n",
    "    S[-1] = 0\n",
    "    F = U.dot(np.diag(S).dot(V))\n",
    "\n",
    "    return F\n",
    "\n",
    "# helper function 2.1: defines an objective function using F and the epipolar constraint\n",
    "def _objective_F(f, pts1, pts2):\n",
    "    F = _singularize(f.reshape([3, 3]))\n",
    "    num_points = pts1.shape[0]\n",
    "    hpts1 = np.concatenate([pts1, np.ones([num_points, 1])], axis=1)\n",
    "    hpts2 = np.concatenate([pts2, np.ones([num_points, 1])], axis=1)\n",
    "    Fp1 = F.dot(hpts1.T)\n",
    "    FTp2 = F.T.dot(hpts2.T)\n",
    "\n",
    "    r = 0\n",
    "    for fp1, fp2, hp2 in zip(Fp1.T, FTp2.T, hpts2):\n",
    "        r += (hp2.dot(fp1))**2 * (1/(fp1[0]**2 + fp1[1]**2) + 1/(fp2[0]**2 + fp2[1]**2))\n",
    "\n",
    "    return r\n",
    "\n",
    "# helper function 2.2: refines F using the objective from above and local optimization\n",
    "def refineF(F, pts1, pts2):\n",
    "    f = scipy.optimize.fmin_powell(\n",
    "        lambda x: _objective_F(x, pts1, pts2), F.reshape([-1]),\n",
    "        maxiter=100000,\n",
    "        maxfun=10000\n",
    "    )\n",
    "\n",
    "    return _singularize(f.reshape([3, 3]))"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualization functions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:12:45.403196Z",
     "start_time": "2024-08-21T17:12:45.387463Z"
    }
   },
   "source": [
    "# helper function 3.1: derives the epipoles using the essential matrix\n",
    "def _epipoles(E):\n",
    "    U, S, V = np.linalg.svd(E)\n",
    "    e1 = V[-1, :]\n",
    "    U, S, V = np.linalg.svd(E.T)\n",
    "    e2 = V[-1, :]\n",
    "\n",
    "    return e1, e2\n",
    "\n",
    "# helper function 3.2: GUI that uses F to draw the epipolar lines in I2 correponding to chosen pts in I1\n",
    "def displayEpipolarF(I1, I2, F):\n",
    "    e1, e2 = _epipoles(F)\n",
    "\n",
    "    sy, sx, _ = I2.shape\n",
    "\n",
    "    f, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 9))\n",
    "    ax1.imshow(I1)\n",
    "    ax1.set_title('Select a point in this image')\n",
    "    ax1.set_axis_off()\n",
    "    ax2.imshow(I2)\n",
    "    ax2.set_title('Verify that the corresponding point \\n is on the epipolar line in this image')\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    while True:\n",
    "        plt.sca(ax1)\n",
    "        x, y = plt.ginput(1, mouse_stop=2)[0]\n",
    "\n",
    "        xc, yc = int(x), int(y)\n",
    "        v = np.array([[xc], [yc], [1]])\n",
    "\n",
    "        l = F @ v\n",
    "        s = np.sqrt(l[0]**2 + l[1]**2)\n",
    "\n",
    "        if s == 0:\n",
    "            raise ValueError('Zero line vector in displayEpipolar')\n",
    "\n",
    "        l = l / s\n",
    "        if l[1] != 0:\n",
    "            xs = 0\n",
    "            xe = sx - 1\n",
    "            ys = -(l[0] * xs + l[2]) / l[1]\n",
    "            ye = -(l[0] * xe + l[2]) / l[1]\n",
    "        else:\n",
    "            ys = 0\n",
    "            ye = sy - 1\n",
    "            xs = -(l[1] * ys + l[2]) / l[0]\n",
    "            xe = -(l[1] * ye + l[2]) / l[0]\n",
    "\n",
    "        ax1.plot(x, y, '*', markersize=6, linewidth=2)  # Corrected markersize\n",
    "        ax2.plot([xs, xe], [ys, ye], linewidth=2)\n",
    "        plt.draw()\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:12:57.782071Z",
     "start_time": "2024-08-21T17:12:50.357842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_eight_point():\n",
    "    # Load the images and corresponding points\n",
    "    data = np.load('data/some_corresp.npz')\n",
    "    pts1 = data['pts1']  # Points in image 1\n",
    "    pts2 = data['pts2']  # Points in image 2\n",
    "\n",
    "    # Load images\n",
    "    I1 = plt.imread('data/im1.png')\n",
    "    I2 = plt.imread('data/im2.png')\n",
    "\n",
    "    # Calculate pmax\n",
    "    pmax = max(I1.shape[0], I1.shape[1])\n",
    "\n",
    "    # Compute the Fundamental Matrix using the Eight Point Algorithm\n",
    "    F = eight_point(pts1, pts2, pmax)\n",
    "\n",
    "    # Print the computed Fundamental Matrix\n",
    "    print(\"Computed Fundamental Matrix F:\")\n",
    "    print(F)\n",
    "\n",
    "    # Visualize the Epipolar Lines using the displayEpipolarF function\n",
    "    displayEpipolarF(I1, I2, F)\n",
    "\n",
    "test_eight_point()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Fundamental Matrix F:\n",
      "[[ 3.56440672e-09 -5.92131870e-08 -1.65029959e-05]\n",
      " [-1.30829066e-07 -1.31095126e-09  1.12471525e-03]\n",
      " [ 3.04775126e-05 -1.08013400e-03 -4.16583180e-03]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 30\u001B[0m\n\u001B[0;32m     27\u001B[0m     displayEpipolarF(I1, I2, F)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# Run the test\u001B[39;00m\n\u001B[1;32m---> 30\u001B[0m \u001B[43mtest_eight_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[6], line 27\u001B[0m, in \u001B[0;36mtest_eight_point\u001B[1;34m()\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(F)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# Visualize the Epipolar Lines using the displayEpipolarF function\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m \u001B[43mdisplayEpipolarF\u001B[49m\u001B[43m(\u001B[49m\u001B[43mI1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mI2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mF\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[5], line 26\u001B[0m, in \u001B[0;36mdisplayEpipolarF\u001B[1;34m(I1, I2, F)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     plt\u001B[38;5;241m.\u001B[39msca(ax1)\n\u001B[1;32m---> 26\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mginput\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmouse_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     28\u001B[0m     xc, yc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(x), \u001B[38;5;28mint\u001B[39m(y)\n\u001B[0;32m     29\u001B[0m     v \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([[xc], [yc], [\u001B[38;5;241m1\u001B[39m]])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:2324\u001B[0m, in \u001B[0;36mginput\u001B[1;34m(n, timeout, show_clicks, mouse_add, mouse_pop, mouse_stop)\u001B[0m\n\u001B[0;32m   2319\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Figure\u001B[38;5;241m.\u001B[39mginput)\n\u001B[0;32m   2320\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mginput\u001B[39m(\n\u001B[0;32m   2321\u001B[0m         n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, show_clicks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   2322\u001B[0m         mouse_add\u001B[38;5;241m=\u001B[39mMouseButton\u001B[38;5;241m.\u001B[39mLEFT, mouse_pop\u001B[38;5;241m=\u001B[39mMouseButton\u001B[38;5;241m.\u001B[39mRIGHT,\n\u001B[0;32m   2323\u001B[0m         mouse_stop\u001B[38;5;241m=\u001B[39mMouseButton\u001B[38;5;241m.\u001B[39mMIDDLE):\n\u001B[1;32m-> 2324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgcf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mginput\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2325\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_clicks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_clicks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2326\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmouse_add\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmouse_add\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmouse_pop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmouse_pop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2327\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmouse_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmouse_stop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\figure.py:3466\u001B[0m, in \u001B[0;36mFigure.ginput\u001B[1;34m(self, n, timeout, show_clicks, mouse_add, mouse_pop, mouse_stop)\u001B[0m\n\u001B[0;32m   3463\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(clicks) \u001B[38;5;241m==\u001B[39m n \u001B[38;5;129;01mand\u001B[39;00m n \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   3464\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mstop_event_loop()\n\u001B[1;32m-> 3466\u001B[0m \u001B[43m_blocking_input\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocking_input_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3467\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbutton_press_event\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkey_press_event\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhandler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3469\u001B[0m \u001B[38;5;66;03m# Cleanup.\u001B[39;00m\n\u001B[0;32m   3470\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mark \u001B[38;5;129;01min\u001B[39;00m marks:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\_blocking_input.py:26\u001B[0m, in \u001B[0;36mblocking_input_loop\u001B[1;34m(figure, event_names, timeout, handler)\u001B[0m\n\u001B[0;32m     24\u001B[0m cids \u001B[38;5;241m=\u001B[39m [figure\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mmpl_connect(name, handler) \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m event_names]\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 26\u001B[0m     \u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_event_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Start event loop.\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:  \u001B[38;5;66;03m# Run even on exception like ctrl-c.\u001B[39;00m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;66;03m# Disconnect the callbacks.\u001B[39;00m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m cid \u001B[38;5;129;01min\u001B[39;00m cids:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backends\\backend_qt.py:421\u001B[0m, in \u001B[0;36mFigureCanvasQT.start_event_loop\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    419\u001B[0m     _ \u001B[38;5;241m=\u001B[39m QtCore\u001B[38;5;241m.\u001B[39mQTimer\u001B[38;5;241m.\u001B[39msingleShot(\u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m), event_loop\u001B[38;5;241m.\u001B[39mquit)\n\u001B[1;32m--> 421\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _maybe_allow_interrupt(event_loop):\n\u001B[0;32m    422\u001B[0m     qt_compat\u001B[38;5;241m.\u001B[39m_exec(event_loop)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:142\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[1;34m(self, typ, value, traceback)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 142\u001B[0m         \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backends\\qt_compat.py:245\u001B[0m, in \u001B[0;36m_maybe_allow_interrupt\u001B[1;34m(qapp)\u001B[0m\n\u001B[0;32m    243\u001B[0m signal\u001B[38;5;241m.\u001B[39msignal(signal\u001B[38;5;241m.\u001B[39mSIGINT, old_sigint_handler)\n\u001B[0;32m    244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handler_args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 245\u001B[0m     \u001B[43mold_sigint_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhandler_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example result:\n",
    "\n",
    "<center> <img src = \"assets/displayEpipolarF_example.jpg\" style=\"width:75%\">\n",
    "<center> Figure 1 - Epipolar lines visualization from \"displayEpipolarF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Epipolar Correpondences\n",
    "---\n",
    "To reconstruct a 3D scene with a pair of two images, we need to find many point pairs. A point pair is two points (one in each image) that correspond to the same 3D scene point. With enough of these pairs, when we plot the resulting 3D points, we will have a rough outline of the 3D object. You found point pairs in HW1 using feature detectors and feature descriptors, and testing a point in one image with every single point in the other image. But here we can use the fundamental matrix to greatly simplify this search.\n",
    "\n",
    "<center> <img src = \"assets/epipolar_theory.jpg\" style=\"width:50%\">\n",
    "<center> Figure 2 - Epipolar Geometry. Potential matches for $p$ lie on the epipolar line $l'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from class that given a point $p$ in one image (the left view in Figure 2). Its corresponding 3D scene point $P$ could lie anywhere along the line from the camera center $C$ to the point $p$. This line, along with a second image's camera center $C'$ (the right view in Figure 2) forms a plane. This plane intersects with the image plane of the second camera, resulting in a line $l'$ in the second image which describes all the possible locations that $p$ may be found in the second image. Line $l'$ is the epipolar line, and we only need to search along this line to find a match for point $p$ found in the first image.\n",
    "\n",
    "* Write the following function:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:13:01.330348Z",
     "start_time": "2024-08-21T17:13:01.316241Z"
    }
   },
   "source": [
    "def epipolar_correspondences(I1, I2, F, pts1, window_size=5):\n",
    "    \"\"\"\n",
    "    Epipolar Correspondences\n",
    "    [I] I1, image 1 (H1xW1 matrix)\n",
    "        I2, image 2 (H2xW2 matrix)\n",
    "        F, fundamental matrix from image 1 to image 2 (3x3 matrix)\n",
    "        pts1, points in image 1 (Nx2 matrix)\n",
    "    [O] pts2, points in image 2 (Nx2 matrix)\n",
    "    \"\"\"\n",
    "    pts2 = []\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    for pt1 in pts1:\n",
    "        x1, y1 = int(pt1[0]), int(pt1[1])\n",
    "        p1 = np.array([x1, y1, 1])\n",
    "\n",
    "        # Compute the epipolar line in the second image\n",
    "        l = F @ p1\n",
    "        l = l / np.sqrt(l[0]**2 + l[1]**2)  # Normalize the line\n",
    "\n",
    "        best_pt2 = None\n",
    "        min_ssd = float('inf')\n",
    "\n",
    "        # Search along the epipolar line\n",
    "        for x2 in range(half_window, I2.shape[1] - half_window):\n",
    "            y2 = int(-(l[0] * x2 + l[2]) / l[1])\n",
    "            if y2 < half_window or y2 >= I2.shape[0] - half_window:\n",
    "                continue\n",
    "\n",
    "            # Extract windows around pt1 in I1 and candidate pt2 in I2\n",
    "            window1 = I1[y1 - half_window:y1 + half_window + 1, x1 - half_window:x1 + half_window + 1]\n",
    "            window2 = I2[y2 - half_window:y2 + half_window + 1, x2 - half_window:x2 + half_window + 1]\n",
    "\n",
    "            # Compute SSD (Sum of Squared Differences)\n",
    "            ssd = np.sum((window1 - window2) ** 2)\n",
    "\n",
    "            if ssd < min_ssd:\n",
    "                min_ssd = ssd\n",
    "                best_pt2 = [x2, y2]\n",
    "\n",
    "        pts2.append(best_pt2)\n",
    "\n",
    "    return np.array(pts2)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `I1` and `I2` are two-view images, `F` is the fundamental matrix computed for the two images using your `eight_point` function, `pts1` is a $N \\times 2$ matrix containing the $(x,y)$ points in the first image, and the function should return `pts2`, a $N \\times 2$ matrix, which contains the corresponding points in the second image. Implementation tips:\n",
    "\n",
    "* To match one point $p$ in image 1, use the fundamental matrix to estimate the corresponding epipolar line $l'$ and generate a set of candidate points in the second image.\n",
    "\n",
    "* For each candidate points $p'$, a similarity score between $p$ and $p'$ is computed. The point among candidates with highest score is treated as epipolar correspondence.\n",
    "\n",
    "* There are many ways to define the similarity between two points. Feel free to use whatever you want and **describe it in your write-up**. One possible solution is to select a small window of size $w$ around the point $p$. Then compare this target window to the window of the candidate point in the second image. For the images we gave you, simple Euclidean distance or Manhattan distance should suffice.\n",
    "\n",
    "* Remember to take care of data type and index range. You can use the provided function `epipolarMatchGUI` to visually test your function. Your function does not need to be perfect, but it should get most easy points correct, like corners, dots etc.\n",
    "\n",
    "* Please include a screenshot of `epipolarMatchGUI` running with your implementation of `epipolar_correspondences` (similar to Figure 3). Mention the similarity metric you decided to use. Also comment on any cases where your matching algorithm consistently fails, and why you might think this is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualization function:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:13:03.312285Z",
     "start_time": "2024-08-21T17:13:03.292143Z"
    }
   },
   "source": [
    "# helper function 4: GUI that uses F, and the matching function to draw the epipolar correpondences on the epipolar lines\n",
    "def epipolarMatchGUI(I1, I2, F):\n",
    "    sy, sx, sd = I2.shape\n",
    "\n",
    "    f, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 9))\n",
    "    ax1.imshow(I1)\n",
    "    ax1.set_title('Select a point in this image')\n",
    "    ax1.set_axis_off()\n",
    "    ax2.imshow(I2)\n",
    "    ax2.set_title('Verify that the corresponding point \\n is on the epipolar line in this image')\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    while True:\n",
    "        plt.sca(ax1)\n",
    "        x, y = plt.ginput(1, mouse_stop=2)[0]\n",
    "\n",
    "        xc, yc = int(x), int(y)\n",
    "        v = np.array([[xc], [yc], [1]])\n",
    "\n",
    "        l = F @ v\n",
    "        s = np.sqrt(l[0]**2 + l[1]**2)\n",
    "\n",
    "        if s == 0:\n",
    "            raise ValueError('Zero line vector in displayEpipolar')\n",
    "\n",
    "        l = l / s\n",
    "        if l[0] != 0:\n",
    "            xs = 0\n",
    "            xe = sx - 1\n",
    "            ys = -(l[0] * xs + l[2]) / l[1]\n",
    "            ye = -(l[0] * xe + l[2]) / l[1]\n",
    "        else:\n",
    "            ys = 0\n",
    "            ye = sy - 1\n",
    "            xs = -(l[1] * ys + l[2]) / l[0]\n",
    "            xe = -(l[1] * ye + l[2]) / l[0]\n",
    "\n",
    "        ax1.plot(x, y, '*', markersize=6, linewidth=2)\n",
    "        ax2.plot([xs, xe], [ys, ye], linewidth=2)\n",
    "\n",
    "        # Draw points\n",
    "        pc = np.array([[xc, yc]])\n",
    "        p2 = epipolar_correspondences(I1, I2, F, pc)\n",
    "        ax2.plot(p2[0, 0], p2[0, 1], 'ro', markersize=8, linewidth=2)\n",
    "        plt.draw()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:13:10.703655Z",
     "start_time": "2024-08-21T17:13:04.019116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_epipolar_correspondences():\n",
    "    # Load the images and corresponding points\n",
    "    data = np.load('data/some_corresp.npz')\n",
    "    pts1 = data['pts1']  # Points in image 1\n",
    "    pts2 = data['pts2']  # Points in image 2\n",
    "\n",
    "    # Load images\n",
    "    I1 = plt.imread('data/im1.png')\n",
    "    I2 = plt.imread('data/im2.png')\n",
    "\n",
    "    # Calculate pmax\n",
    "    pmax = max(I1.shape[0], I1.shape[1])\n",
    "\n",
    "    # Compute the Fundamental Matrix using the Eight Point Algorithm\n",
    "    F = eight_point(pts1, pts2, pmax)\n",
    "\n",
    "    # Visualize the Epipolar Correspondences using the GUI\n",
    "    epipolarMatchGUI(I1, I2, F)\n",
    "\n",
    "# Run the test\n",
    "test_epipolar_correspondences()"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 21\u001B[0m\n\u001B[0;32m     18\u001B[0m     epipolarMatchGUI(I1, I2, F)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Run the test\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[43mtest_epipolar_correspondences\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 18\u001B[0m, in \u001B[0;36mtest_epipolar_correspondences\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m F \u001B[38;5;241m=\u001B[39m eight_point(pts1, pts2, pmax)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Visualize the Epipolar Correspondences using the GUI\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[43mepipolarMatchGUI\u001B[49m\u001B[43m(\u001B[49m\u001B[43mI1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mI2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mF\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 15\u001B[0m, in \u001B[0;36mepipolarMatchGUI\u001B[1;34m(I1, I2, F)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     plt\u001B[38;5;241m.\u001B[39msca(ax1)\n\u001B[1;32m---> 15\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mginput\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmouse_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     17\u001B[0m     xc, yc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(x), \u001B[38;5;28mint\u001B[39m(y)\n\u001B[0;32m     18\u001B[0m     v \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([[xc], [yc], [\u001B[38;5;241m1\u001B[39m]])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:2324\u001B[0m, in \u001B[0;36mginput\u001B[1;34m(n, timeout, show_clicks, mouse_add, mouse_pop, mouse_stop)\u001B[0m\n\u001B[0;32m   2319\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Figure\u001B[38;5;241m.\u001B[39mginput)\n\u001B[0;32m   2320\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mginput\u001B[39m(\n\u001B[0;32m   2321\u001B[0m         n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, show_clicks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   2322\u001B[0m         mouse_add\u001B[38;5;241m=\u001B[39mMouseButton\u001B[38;5;241m.\u001B[39mLEFT, mouse_pop\u001B[38;5;241m=\u001B[39mMouseButton\u001B[38;5;241m.\u001B[39mRIGHT,\n\u001B[0;32m   2323\u001B[0m         mouse_stop\u001B[38;5;241m=\u001B[39mMouseButton\u001B[38;5;241m.\u001B[39mMIDDLE):\n\u001B[1;32m-> 2324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgcf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mginput\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2325\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_clicks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_clicks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2326\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmouse_add\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmouse_add\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmouse_pop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmouse_pop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2327\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmouse_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmouse_stop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\figure.py:3466\u001B[0m, in \u001B[0;36mFigure.ginput\u001B[1;34m(self, n, timeout, show_clicks, mouse_add, mouse_pop, mouse_stop)\u001B[0m\n\u001B[0;32m   3463\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(clicks) \u001B[38;5;241m==\u001B[39m n \u001B[38;5;129;01mand\u001B[39;00m n \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   3464\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mstop_event_loop()\n\u001B[1;32m-> 3466\u001B[0m \u001B[43m_blocking_input\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocking_input_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3467\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbutton_press_event\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkey_press_event\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhandler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3469\u001B[0m \u001B[38;5;66;03m# Cleanup.\u001B[39;00m\n\u001B[0;32m   3470\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mark \u001B[38;5;129;01min\u001B[39;00m marks:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\_blocking_input.py:26\u001B[0m, in \u001B[0;36mblocking_input_loop\u001B[1;34m(figure, event_names, timeout, handler)\u001B[0m\n\u001B[0;32m     24\u001B[0m cids \u001B[38;5;241m=\u001B[39m [figure\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mmpl_connect(name, handler) \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m event_names]\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 26\u001B[0m     \u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_event_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Start event loop.\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:  \u001B[38;5;66;03m# Run even on exception like ctrl-c.\u001B[39;00m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;66;03m# Disconnect the callbacks.\u001B[39;00m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m cid \u001B[38;5;129;01min\u001B[39;00m cids:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backends\\backend_qt.py:421\u001B[0m, in \u001B[0;36mFigureCanvasQT.start_event_loop\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    419\u001B[0m     _ \u001B[38;5;241m=\u001B[39m QtCore\u001B[38;5;241m.\u001B[39mQTimer\u001B[38;5;241m.\u001B[39msingleShot(\u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m), event_loop\u001B[38;5;241m.\u001B[39mquit)\n\u001B[1;32m--> 421\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _maybe_allow_interrupt(event_loop):\n\u001B[0;32m    422\u001B[0m     qt_compat\u001B[38;5;241m.\u001B[39m_exec(event_loop)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:142\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[1;34m(self, typ, value, traceback)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 142\u001B[0m         \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backends\\qt_compat.py:245\u001B[0m, in \u001B[0;36m_maybe_allow_interrupt\u001B[1;34m(qapp)\u001B[0m\n\u001B[0;32m    243\u001B[0m signal\u001B[38;5;241m.\u001B[39msignal(signal\u001B[38;5;241m.\u001B[39mSIGINT, old_sigint_handler)\n\u001B[0;32m    244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handler_args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 245\u001B[0m     \u001B[43mold_sigint_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhandler_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* Example result:\n",
    "\n",
    "<center> <img src = \"assets/epipolarMatchGUI_example.jpg\" style=\"width:75%\">\n",
    "<center> Figure 3 - Epipolar Match visualization. A few errors are alright, but it should get most easy points correct (corners, dots, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Essential Matrix\n",
    "---\n",
    "In order to get the full camera projection matrices we need to compute the Essential matrix. So far, we have only been using the Fundamental matrix.\n",
    "\n",
    "* Write the following function:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:13:14.234092Z",
     "start_time": "2024-08-21T17:13:14.229578Z"
    }
   },
   "source": [
    "def essential_matrix(F, K1, K2):\n",
    "    \"\"\"\n",
    "    Essential Matrix\n",
    "    [I] F, the fundamental matrix (3x3 matrix)\n",
    "        K1, camera matrix 1 (3x3 matrix)\n",
    "        K2, camera matrix 2 (3x3 matrix)\n",
    "    [O] E, the essential matrix (3x3 matrix)\n",
    "    \"\"\"\n",
    "    E = K2.T @ F @ K1\n",
    "    return E"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:13:14.916588Z",
     "start_time": "2024-08-21T17:13:14.903068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_essential_matrix():\n",
    "    # Load the images and corresponding points\n",
    "    data = np.load('data/some_corresp.npz')\n",
    "    pts1 = data['pts1']  # Points in image 1\n",
    "    pts2 = data['pts2']  # Points in image 2\n",
    "    \n",
    "    # Load the intrinsic matrices\n",
    "    intrinsics = np.load('data/intrinsics.npz')\n",
    "    K1 = intrinsics['K1']\n",
    "    K2 = intrinsics['K2']\n",
    "    \n",
    "    # Calculate pmax\n",
    "    pmax = max(pts1.shape[0], pts1.shape[1])\n",
    "    \n",
    "    # Compute the Fundamental Matrix using the Eight Point Algorithm\n",
    "    F = eight_point(pts1, pts2, pmax)\n",
    "    \n",
    "    # Compute the Essential Matrix\n",
    "    E = essential_matrix(F, K1, K2)\n",
    "    \n",
    "    # Print the computed Essential Matrix\n",
    "    print(\"Computed Essential Matrix E:\")\n",
    "    print(E)\n",
    "    \n",
    "# Run the test\n",
    "test_essential_matrix()\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Essential Matrix E:\n",
      "[[ 4.60261645e-02 -8.37143325e-01 -2.62254028e-01]\n",
      " [-1.73129035e+00 -1.81926284e-02  9.65216091e+00]\n",
      " [-8.88283922e-03 -9.77247828e+00 -1.64220428e-02]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `F` is the Fundamental matrix computed between two images, `K1` and `K2` are the intrinsic camera matrices for the first and second image respectively (contained in `data/intrinsics.npz`), and `E` is the computed essential matrix. The intrinsic camera parameters are typically acquired through camera calibration. Refer to the class slides for the\n",
    "relationship between the Fundamental matrix and the Essential matrix.\n",
    "\n",
    "* Please include your estimated $E$ matrix for the temple image pair in the PDF report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 - Triangulation\n",
    "---\n",
    "Write a function to triangulate pairs of 2D points in the images to a set of 3D points.\n",
    "\n",
    "* Write the following function:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:13:19.384336Z",
     "start_time": "2024-08-21T17:13:19.365994Z"
    }
   },
   "source": [
    "def triangulate(M1, pts1, M2, pts2):\n",
    "    \"\"\"\n",
    "    Triangulation\n",
    "    [I] M1, camera projection matrix 1 (3x4 matrix)\n",
    "        pts1, points in image 1 (Nx2 matrix)\n",
    "        M2, camera projection matrix 2 (3x4 matrix)\n",
    "        pts2, points in image 2 (Nx2 matrix)\n",
    "    [O] pts3d, 3D points in space (Nx3 matrix)\n",
    "    \"\"\"\n",
    "    num_points = pts1.shape[0]\n",
    "    pts3d = np.zeros((num_points, 3))\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        x1, y1 = pts1[i]\n",
    "        x2, y2 = pts2[i]\n",
    "        \n",
    "        # Create the system of linear equations\n",
    "        A = np.array([\n",
    "            x1 * M1[2] - M1[0],\n",
    "            y1 * M1[2] - M1[1],\n",
    "            x2 * M2[2] - M2[0],\n",
    "            y2 * M2[2] - M2[1]\n",
    "        ])\n",
    "        \n",
    "        # Solve for the 3D point using SVD\n",
    "        _, _, V = np.linalg.svd(A)\n",
    "        X = V[-1]\n",
    "        X = X / X[3]  # Normalize to make it a homogeneous coordinate\n",
    "        \n",
    "        pts3d[i] = X[:3]\n",
    "    \n",
    "    return pts3d\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `pts1` and `pts2` are the $N\\times 2$ matrices with the 2D image coordinates, `M1` and `M2` are the $3\\times4$ camera projection matrices and `pts3d` is an $N\\times 3$ matrix with the corresponding 3D points (in all cases, one point per row). Remember that you will need to multiply the given intrinsic matrices with your solution for the extrinsic camera matrices to obtain the final camera projection matrices. \n",
    "\n",
    "* For `M1` you can assume no rotation or translation, so the extrinsic matrix is just $\\left[I \\lvert 0\\right]$. \n",
    "\n",
    "* For `M2`, pass the essential matrix to the provided function `camera2` to get four possible **extrinsic** matrices. You will need to determine which of these is the correct one to use. Refer to the class slides to remind yourself of the 4 possible camera layouts. The correct configuration is the one for which most of the 3D points are in front of both cameras (i.e. have a positive depth), and make up a reasonable recovered shape. To make sure you choose the right one, write a helper function that apply the extrinsics of camera 2 to the recovered 3D points and check that they are still in front of camera 1 (positive $Z$).\n",
    "\n",
    "* Keep in mind to multiply the extrinsics matrices by the corresponding intrinsics before inputting them to `triangulate`.\n",
    "* Once implemented, check the performance by looking at the re-projection error. To compute the re-projection error, project the estimated 3D points back to the image 1 and compute the mean Euclidean error between projected 2D points and the given `pts1`.\n",
    "\n",
    "* **In your write-up**: Describe how you determined which extrinsic matrix is correct. Note that simply rewording the hint is not enough. Report your re-projection error using the given `pts1` and `pts2` in `data/some_corresp.npz`. If implemented correctly, the re-projection error should be less than 2 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:13:21.262066Z",
     "start_time": "2024-08-21T17:13:21.253476Z"
    }
   },
   "source": [
    "# helper function 5: returns the 4 options for camera matrix M2 given the essential matrix\n",
    "def camera2(E):\n",
    "    U,S,V = np.linalg.svd(E)\n",
    "    m = S[:2].mean()\n",
    "    E = U.dot(np.array([[m,0,0], [0,m,0], [0,0,0]])).dot(V)\n",
    "    U,S,V = np.linalg.svd(E)\n",
    "    W = np.array([[0,-1,0], [1,0,0], [0,0,1]])\n",
    "\n",
    "    if np.linalg.det(U.dot(W).dot(V))<0:\n",
    "        W = -W\n",
    "\n",
    "    M2s = np.zeros([3,4,4])\n",
    "    M2s[:,:,0] = np.concatenate([U.dot(W).dot(V), U[:,2].reshape([-1, 1])/abs(U[:,2]).max()], axis=1)\n",
    "    M2s[:,:,1] = np.concatenate([U.dot(W).dot(V), -U[:,2].reshape([-1, 1])/abs(U[:,2]).max()], axis=1)\n",
    "    M2s[:,:,2] = np.concatenate([U.dot(W.T).dot(V), U[:,2].reshape([-1, 1])/abs(U[:,2]).max()], axis=1)\n",
    "    M2s[:,:,3] = np.concatenate([U.dot(W.T).dot(V), -U[:,2].reshape([-1, 1])/abs(U[:,2]).max()], axis=1)\n",
    "\n",
    "    return M2s\n",
    "\n",
    "def find_correct_M2(M1, pts1, M2s, pts2, K1, K2):\n",
    "    best_M2 = None\n",
    "    max_positive_depth = 0\n",
    "    \n",
    "    for i in range(4):\n",
    "        M2 = M2s[:, :, i]\n",
    "        P = triangulate(M1, pts1, K2 @ M2, pts2)\n",
    "        \n",
    "        # Check how many points are in front of both cameras\n",
    "        num_positive_depth = np.sum(P[:, 2] > 0)\n",
    "        \n",
    "        if num_positive_depth > max_positive_depth:\n",
    "            max_positive_depth = num_positive_depth\n",
    "            best_M2 = M2\n",
    "    \n",
    "    return best_M2\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:32:59.319411Z",
     "start_time": "2024-08-21T17:32:59.265068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_reprojection_error(pts3d, M1, M2, pts1, pts2):\n",
    "    \"\"\"\n",
    "    Compute the re-projection error.\n",
    "    [I] pts3d, 3D points in space (Nx3 matrix)\n",
    "        M1, camera projection matrix 1 (3x4 matrix)\n",
    "        M2, camera projection matrix 2 (3x4 matrix)\n",
    "        pts1, original points in image 1 (Nx2 matrix)\n",
    "        pts2, original points in image 2 (Nx2 matrix)\n",
    "    [O] error, the re-projection error (scalar)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert 3D points to homogeneous coordinates\n",
    "    pts3d_homogeneous = np.hstack((pts3d, np.ones((pts3d.shape[0], 1))))\n",
    "\n",
    "    # Project the 3D points back onto the image planes\n",
    "    projected_pts1_homogeneous = (M1 @ pts3d_homogeneous.T).T\n",
    "    projected_pts2_homogeneous = (M2 @ pts3d_homogeneous.T).T\n",
    "\n",
    "    # Convert back to 2D coordinates by dividing by the third coordinate\n",
    "    projected_pts1 = projected_pts1_homogeneous[:, :2] / projected_pts1_homogeneous[:, 2].reshape(-1, 1)\n",
    "    projected_pts2 = projected_pts2_homogeneous[:, :2] / projected_pts2_homogeneous[:, 2].reshape(-1, 1)\n",
    "\n",
    "    # Compute the Euclidean distance (re-projection error) between original and projected points\n",
    "    error1 = np.linalg.norm(pts1 - projected_pts1, axis=1)\n",
    "    print(f\"Re-projection error 1: {error1.mean()}\")\n",
    "    error2 = np.linalg.norm(pts2 - projected_pts2, axis=1)\n",
    "    print(f\"Re-projection error 2: {error2.mean()}\")\n",
    "\n",
    "    # Calculate the mean re-projection error\n",
    "    total_error = np.mean(np.hstack((error1, error2)))\n",
    "\n",
    "    return total_error\n",
    "\n",
    "def test_reprojection_error():\n",
    "    # Load necessary data\n",
    "    data = np.load('data/some_corresp.npz')\n",
    "    pts1 = data['pts1']  # Points in image 1\n",
    "    pts2 = data['pts2']  # Points in image 2\n",
    "    intrinsics = np.load('data/intrinsics.npz')\n",
    "    K1 = intrinsics['K1']\n",
    "    K2 = intrinsics['K2']\n",
    "\n",
    "    # Load images\n",
    "    I1 = plt.imread('data/im1.png')\n",
    "    I2 = plt.imread('data/im2.png')\n",
    "\n",
    "    # Compute the Fundamental Matrix using the Eight Point Algorithm\n",
    "    F = eight_point(pts1, pts2, max(I1.shape))\n",
    "\n",
    "    # Compute the Essential Matrix\n",
    "    E = essential_matrix(F, K1, K2)\n",
    "\n",
    "    # Compute the first camera projection matrix M1\n",
    "    M1 = K1 @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "\n",
    "    # Get the four possible M2s\n",
    "    M2s = camera2(E)\n",
    "\n",
    "    # Find the correct M2\n",
    "    M2 = find_correct_M2(M1, pts1, M2s, pts2, K1, K2)\n",
    "\n",
    "    # Triangulate to find the 3D points\n",
    "    pts3d = triangulate(M1, pts1, K2 @ M2, pts2)\n",
    "\n",
    "    # Compute the re-projection error\n",
    "    error = compute_reprojection_error(pts3d, M1, K2 @ M2, pts1, pts2)\n",
    "\n",
    "    print(f\"Mean Re-projection error: {error:.4f} pixels\")\n",
    "\n",
    "test_reprojection_error()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-projection error 1: 0.4694339612615537\n",
      "Re-projection error 2: 0.46861357015407\n",
      "Mean Re-projection error: 0.4690 pixels\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 - Putting It All Together\n",
    "---\n",
    "You now have all the pieces you need to generate a full 3D reconstruction. Write a test script `test_temple_coords` that does the following:\n",
    "\n",
    "* Load the two images and the point correspondences from `data/some_corresp.npz`.\n",
    "* Run eight point to compute the fundamental matrix `F`.\n",
    "* Load the points in image 1 contained in `data/temple_coords.npz` and run your `epipolar_correspondences` on them to get the corresponding points in image 2.\n",
    "* Load `data/intrinsics.npz` and compute the essential matrix `E`.\n",
    "* Compute the first camera projection matrix `M1` and use `camera2` to compute the four candidates for `M2`.\n",
    "* Run your `triangulate` function using the four sets of camera matrix candidates (after scaling with the intrinsics), the points from `data/temple_coords.npz`, and their computed correspondences.\n",
    "* Figure out the correct `M2` and the corresponding 3D points.\n",
    "* Use matplotlib's scatter function to plot these point correspondences on screen.\n",
    "* Report your computed extrinsic parameters (`R1`,`R2`,`t1`,`t2`) in your PDF.\n",
    "* We will use your test script to run your code, so be sure it runs smoothly. In particular, use relative paths to load files, not absolute paths.\n",
    "* **In your write-up**: Include 3 images of your final reconstruction of the points given in the file `data/temple_coords.npz`, from different angles as shown in Figure 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example result:\n",
    "\n",
    "<center> <img src = \"assets/pointcloud_example.jpg\" style=\"width:75%\">\n",
    "<center> Figure 4 - Sample Reconstructions."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:22:28.439881Z",
     "start_time": "2024-08-21T17:22:27.085637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_temple_coords():\n",
    "    # Load the images and corresponding points\n",
    "    data = np.load('data/some_corresp.npz')\n",
    "    pts1 = data['pts1']  # Points in image 1\n",
    "    pts2 = data['pts2']  # Points in image 2\n",
    "    temple_data = np.load('data/temple_coords.npz')\n",
    "    temple_pts1 = temple_data['pts1']  # Points in image 1 for temple\n",
    "    \n",
    "    # Load intrinsics\n",
    "    intrinsics = np.load('data/intrinsics.npz')\n",
    "    K1 = intrinsics['K1']\n",
    "    K2 = intrinsics['K2']\n",
    "\n",
    "    # Load images\n",
    "    I1 = plt.imread('data/im1.png')\n",
    "    I2 = plt.imread('data/im2.png')\n",
    "\n",
    "    # Compute the Fundamental Matrix using the Eight Point Algorithm\n",
    "    F = eight_point(pts1, pts2, max(I1.shape))\n",
    "\n",
    "    # Compute corresponding points in image 2 for the temple points\n",
    "    temple_pts2 = epipolar_correspondences(I1, I2, F, temple_pts1)\n",
    "\n",
    "    # Compute the Essential Matrix\n",
    "    E = essential_matrix(F, K1, K2)\n",
    "\n",
    "    # Compute the first camera projection matrix M1\n",
    "    M1 = K1 @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "\n",
    "    # Get the four possible M2s\n",
    "    M2s = camera2(E)\n",
    "\n",
    "    # Find the correct M2\n",
    "    M2 = find_correct_M2(M1, temple_pts1, M2s, temple_pts2, K1, K2)\n",
    "\n",
    "    # Triangulate to find the 3D points\n",
    "    P = triangulate(M1, temple_pts1, K2 @ M2, temple_pts2)\n",
    "\n",
    "    # Visualize the 3D points using matplotlib's scatter function\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(P[:, 0], P[:, 1], P[:, 2], c='r', marker='o')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Report the extrinsic parameters of M2\n",
    "    R2 = M2[:, :3]\n",
    "    t2 = M2[:, 3]\n",
    "    print(\"Extrinsic Parameters for M2:\")\n",
    "    print(\"R2:\\n\", R2)\n",
    "    print(\"t2:\\n\", t2)\n",
    "\n",
    "test_temple_coords()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrinsic Parameters for M2:\n",
      "R2:\n",
      " [[ 9.65189813e-01 -2.84559523e-02  2.59997852e-01]\n",
      " [ 2.73497924e-02  9.99594929e-01  7.87192866e-03]\n",
      " [-2.60116537e-01 -4.87018080e-04  9.65577107e-01]]\n",
      "t2:\n",
      " [-1.         -0.02745167  0.08201567]\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
